@misc{stablediffusion,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2021},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{riffusion,
  author = {Forsgren, Seth* and Martiros, Hayk*},
  title = {{Riffusion - Stable diffusion for real-time music generation}},
  url = {https://riffusion.com/about},
  year = {2022}
}


@article{analysis_generative,
  title={The Analysis of Generative Music Programs},
  volume={13},
  DOI={10.1017/S1355771808000332},
  number={3},
  journal={Organised Sound},
  publisher={Cambridge University Press},
  author={Collins, Nick},
  year={2008},
  pages={237–248}
}


@misc{neato,
  doi = {10.48550/ARXIV.2202.02171},
  url = {https://arxiv.org/abs/2202.02171},
  author = {Rückert, Darius and Wang, Yuanhao and Li, Rui and Idoughi, Ramzi and Heidrich, Wolfgang},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR), Image and Video Processing (eess.IV), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  title = {NeAT: Neural Adaptive Tomography},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}

@inproceedings{evolutionary_puredata,
author = {Macret, Matthieu and Pasquier, Philippe},
title = {Automatic Design of Sound Synthesizers as Pure Data Patches Using Coevolutionary Mixed-Typed Cartesian Genetic Programming},
year = {2014},
isbn = {9781450326629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2576768.2598303},
doi = {10.1145/2576768.2598303},
abstract = {A sound synthesizer can be defined as a program that takes a few input parameters and returns a sound. The general sound synthesis problem could then be formulated as: given a sound (or a set of sounds) what program and set of input parameters can generate that sound (set of sounds)? We propose a novel approach to tackle this problem in which we represent sound synthesizers using Pure Data (Pd), a graphic programming language for digital signal processing. We search the space of possible sound synthesizers using Coevolutionary Mixed-typed Cartesian Genetic Programming (MT-CGP), and the set of input parameters using a standard Genetic Algorithm (GA). The proposed algorithm co-evolves a population of MT-CGP graphs, representing the functional forms of synthesizers, and a population of GA chromosomes, representing their inputs parameters. A fitness function based on the Mel-frequency Cepstral Coefficients (MFCC) evaluates the distance between the target and produced sounds. Our approach is capable of suggesting novel functional forms and input parameters, suitable to approximate a given target sound (and we hope in future iterations a set of sounds). Since the resulting synthesizers are presented as Pd patches, the user can experiment, interact with, and reuse them.},
booktitle = {Proceedings of the 2014 Annual Conference on Genetic and Evolutionary Computation},
pages = {309–316},
numpages = {8},
keywords = {coevolution, cartesian genetic programming, sound synthesis},
location = {Vancouver, BC, Canada},
series = {GECCO '14}
}

@INPROCEEDINGS{computer_vision_music_identification,
  author={Yan Ke and Hoiem, D. and Sukthankar, R.},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)}, 
  title={Computer vision for music identification}, 
  year={2005},
  volume={1},
  number={},
  pages={597-604 vol. 1},
  doi={10.1109/CVPR.2005.105}
}


@ARTICLE{sliding_fourier,
  author={Jacobsen, E. and Lyons, R.},
  journal={IEEE Signal Processing Magazine}, 
  title={The sliding DFT}, 
  year={2003},
  volume={20},
  number={2},
  pages={74-80},
  doi={10.1109/MSP.2003.1184347}
}


@inproceedings{torchsynth,
	title        = {One Billion Audio Sounds from {GPU}-enabled Modular Synthesis},
	author       = {Joseph Turian and Jordie Shier and George Tzanetakis and Kirk McNally and Max Henry},
	year         = 2021,
	month        = Sep,
	booktitle    = {Proceedings of the 23rd International Conference on Digital Audio Effects (DAFx2020)},
	location     = {Vienna, Austria}
}


@inproceedings{gpu_drum,
    title = {GPU-Accelerated Physical Model For Real-time Drumhead Synthesis},
    year = 2022,
    author={Gaster, Benedict. R. and Challinor, Ryan.},
    url = {https://muses-dmi.github.io/pm_gpus/gpu_accelerated_physical_model_for_real_time_drumhead_synthesis/}
}

