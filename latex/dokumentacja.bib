@misc{stablediffusion,
  title = {High-Resolution Image Synthesis with Latent Diffusion Models},
  author = {Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick
            Esser and Björn Ommer},
  year = {2021},
  eprint = {2112.10752},
  archivePrefix = {arXiv},
  primaryClass = {cs.CV},
}

@article{riffusion,
  author = {Forsgren, Seth* and Martiros, Hayk*},
  title = {{Riffusion - Stable diffusion for real-time music generation}},
  url = {https://riffusion.com/about},
  year = {2022},
}

@online{minilogue_diagram,
  title = {Korg Minilogue xd User Manual},
  note = {\url{ https://www.korg.com/us/support/download/product/0/811/ }},
  author = {KORG},
  year = {2017},
}

@article{kacprzak2010inteligentne,
  title = {Inteligentne metody rozpoznawania d{\'z}wi{\k{e}}ku},
  author = {Kacprzak, Stanis{\l}aw},
}

@online{digitone_manual,
  title = {Elektron Digitone User Manual},
  note = {\url{
          https://cdn.www.elektron.se/media/downloads/digitone/Digitone_User_Manual_ENG_OS1.40A_221123.pdf
          }},
  author = {Elektron},
  year = {2022},
}

@online{ladder_filter_rust,
  title = {Ladder filter implementation},
  note = {\url{
          https://github.com/RustAudio/vst-rs/blob/master/examples/ladder_filter.rs
          }},
}

@online{yamaha_dx7_manual,
  title = {Yamaha DX7 user manual},
  note = {\url{
          https://usa.yamaha.com/files/download/other_assets/9/333979/DX7E1.pdf}},
}

@online{yamaha_vl1_manual,
  title = {Yamaha VL1 user manual},
  note = {\url{
          https://europe.yamaha.com/files/download/other_assets/9/321049/VL1E1.pdf
          }},
}

@online{microcosm_hologram_manual,
  title = {Microcosm Hologram user manual},
  note = {\url{
          https://www.hologramelectronics.com/_files/ugd/74428b_c4e6e20555914198bdb59c12f9a9e4d4.pdf
          }},
}

@online{proc_macro,
  title = {The Rust Reference - Procedural Macros},
  note = {\url{https://doc.rust-lang.org/reference/procedural-macros.html}},
  year = {2023},
}

@online{maturin,
  title = {Maturin - Build and publish crates with pyo3, rust-cpython, cffi and
           uniffi bindings as well as rust binaries as python packages.},
  note = {\url{https://github.com/PyO3/maturin}},
  year = {2023},
}

@online{python_extension_module,
  title = {Python documentation - Extending Python with C or C++},
  note = {\url{https://www.korg.com/us/support/download/manual/0/811/4277/}},
  author = {Python Software Foundation},
  year = {2019},
}

@inproceedings{librosa,
  author = {McFee, Brian and Raffel, Colin and Liang, Dawen and Ellis, Daniel
            and Mcvicar, Matt and Battenberg, Eric and Nieto, Oriol},
  year = {2015},
  month = {01},
  pages = {18-24},
  title = {librosa: Audio and Music Signal Analysis in Python},
  doi = {10.25080/Majora-7b98e3ed-003},
}

@inproceedings{yin_pitch_estimation,
  author = {Mauch, Matthias and Dixon, Simon},
  booktitle = {2014 IEEE International Conference on Acoustics, Speech and
               Signal Processing (ICASSP)},
  title = {PYIN: A fundamental frequency estimator using probabilistic threshold
           distributions},
  year = {2014},
  volume = {},
  number = {},
  pages = {659-663},
  doi = {10.1109/ICASSP.2014.6853678},
}


@online{bespoke,
  title = {Bespoke Synth - a modular DAW for Mac, Windows, and Linux.},
  note = {\url{https://www.bespokesynth.com/}},
  author = {Ryan Challinor},
  year = {2023},
}

@online{eurorack,
  title = "Eurorack standard - Wikipedia article",
  note = {Dostępny na \url{https://en.wikipedia.org/wiki/Eurorack}},
}

@online{transient_music_theory,
  title = "Transient (acoustics)",
  note = {Dostępny na \url{https://en.wikipedia.org/wiki/Transient_(acoustics)}},
}

@online{vcvrack,
  title = "VCV Rack - Virtual Eurorack Studio",
  note = {\url{https://vcvrack.com/}},
}

@online{pure_data,
  title = {Pure Data - an open source visual programming language for multimedia
           },
  note = {\url{https://puredata.info/}},
  year = {2023},
}

@article{analysis_generative,
  title = {The Analysis of Generative Music Programs},
  volume = {13},
  DOI = {10.1017/S1355771808000332},
  number = {3},
  journal = {Organised Sound},
  publisher = {Cambridge University Press},
  author = {Collins, Nick},
  year = {2008},
  pages = {237–248},
}

@inproceedings{engel2020ddsp,
  title = {DDSP: Differentiable Digital Signal Processing},
  author = {Jesse Engel and Lamtharn (Hanoi) Hantrakul and Chenjie Gu and Adam
            Roberts},
  booktitle = {International Conference on Learning Representations},
  year = {2020},
  note = {\url{https://openreview.net/forum?id=B1x1ma4tDr}},
}

@misc{engel2017neural,
  title = {Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders},
  author = {Jesse Engel and Cinjon Resnick and Adam Roberts and Sander Dieleman
            and Douglas Eck and Karen Simonyan and Mohammad Norouzi},
  year = {2017},
  eprint = {1704.01279},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
}

@misc{neato,
  doi = {10.48550/ARXIV.2202.02171},
  note = {\url{https://arxiv.org/abs/2202.02171}},
  author = {Rückert, Darius and Wang, Yuanhao and Li, Rui and Idoughi, Ramzi and
            Heidrich, Wolfgang},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR),
              Image and Video Processing (eess.IV), FOS: Computer and information
              sciences, FOS: Computer and information sciences, FOS: Electrical
              engineering, electronic engineering, information engineering, FOS:
              Electrical engineering, electronic engineering, information
              engineering},
  title = {NeAT: Neural Adaptive Tomography},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0
               International},
}

@online{evolutionary_puredata_results,
  author = {Macret, Matthieu and Pasquier, Philippe},
  title = {Automatic Design of Sound Synthesizers as Pure Data Patches Using
           Coevolutionary Mixed-Typed Cartesian Genetic Programming -- trained
           sounds},
  note = {\url{https://metacreation.net/mmacret/GECCO2014}},
}

@inproceedings{evolutionary_puredata,
  author = {Macret, Matthieu and Pasquier, Philippe},
  title = {Automatic Design of Sound Synthesizers as Pure Data Patches Using
           Coevolutionary Mixed-Typed Cartesian Genetic Programming},
  year = {2014},
  isbn = {9781450326629},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/2576768.2598303},
  doi = {10.1145/2576768.2598303},
  abstract = {A sound synthesizer can be defined as a program that takes a few
              input parameters and returns a sound. The general sound synthesis
              problem could then be formulated as: given a sound (or a set of
              sounds) what program and set of input parameters can generate that
              sound (set of sounds)? We propose a novel approach to tackle this
              problem in which we represent sound synthesizers using Pure Data
              (Pd), a graphic programming language for digital signal processing.
              We search the space of possible sound synthesizers using
              Coevolutionary Mixed-typed Cartesian Genetic Programming (MT-CGP),
              and the set of input parameters using a standard Genetic Algorithm
              (GA). The proposed algorithm co-evolves a population of MT-CGP
              graphs, representing the functional forms of synthesizers, and a
              population of GA chromosomes, representing their inputs parameters.
              A fitness function based on the Mel-frequency Cepstral Coefficients
              (MFCC) evaluates the distance between the target and produced
              sounds. Our approach is capable of suggesting novel functional
              forms and input parameters, suitable to approximate a given target
              sound (and we hope in future iterations a set of sounds). Since the
              resulting synthesizers are presented as Pd patches, the user can
              experiment, interact with, and reuse them.},
  booktitle = {Proceedings of the 2014 Annual Conference on Genetic and
               Evolutionary Computation},
  pages = {309–316},
  numpages = {8},
  keywords = {coevolution, cartesian genetic programming, sound synthesis},
  location = {Vancouver, BC, Canada},
  series = {GECCO '14},
}

@inproceedings{computer_vision_music_identification,
  author = {Yan Ke and Hoiem, D. and Sukthankar, R.},
  booktitle = {2005 IEEE Computer Society Conference on Computer Vision and
               Pattern Recognition (CVPR'05)},
  title = {Computer vision for music identification},
  year = {2005},
  volume = {1},
  number = {},
  pages = {597-604 vol. 1},
  doi = {10.1109/CVPR.2005.105},
}

@article{sliding_fourier,
  author = {Jacobsen, E. and Lyons, R.},
  journal = {IEEE Signal Processing Magazine},
  title = {The sliding DFT},
  year = {2003},
  volume = {20},
  number = {2},
  pages = {74-80},
  doi = {10.1109/MSP.2003.1184347},
}


@inproceedings{torchsynth,
  title = {One Billion Audio Sounds from {GPU}-enabled Modular Synthesis},
  author = {Joseph Turian and Jordie Shier and George Tzanetakis and Kirk
            McNally and Max Henry},
  year = 2021,
  month = Sep,
  booktitle = {Proceedings of the 23rd International Conference on Digital Audio
               Effects (DAFx2020)},
  location = {Vienna, Austria},
}

@inproceedings{gpu_drum,
  title = {GPU-Accelerated Physical Model For Real-time Drumhead Synthesis},
  year = 2022,
  author = {Gaster, Benedict. R. and Challinor, Ryan.},
  url = {
         https://muses-dmi.github.io/pm_gpus/gpu_accelerated_physical_model_for_real_time_drumhead_synthesis/
         },
}


@misc{ddx7,
  doi = {10.48550/ARXIV.2208.06169},
  url = {https://arxiv.org/abs/2208.06169},
  author = {Caspe, Franco and McPherson, Andrew and Sandler, Mark},
  keywords = {Sound (cs.SD), Machine Learning (cs.LG), Audio and Speech
              Processing (eess.AS), Signal Processing (eess.SP), FOS: Computer
              and information sciences, FOS: Computer and information sciences,
              FOS: Electrical engineering, electronic engineering, information
              engineering, FOS: Electrical engineering, electronic engineering,
              information engineering, H.5.5; I.2.6},
  title = {DDX7: Differentiable FM Synthesis of Musical Instrument Sounds},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license},
}

@book{digital_filters,
  AUTHOR = "Julius O. Smith",
  TITLE = "Introduction to Digital Filters with Audio Applications",
  PUBLISHER = "W3K Publishing",
  ADDRESS = "\url{http://www.w3k.org/books/}",
  YEAR = 2007,
  ISBN = "978-0-9745607-1-7",
}

@article{freeverb,
  AUTHOR = "Julius O. Smith",
  year = 2010,
  TITLE = "Physical Signal Audio Processing",
  ADDRESS = "https://ccrma.stanford.edu/~jos/pasp/Freeverb.html",
}

@article{reverb,
  AUTHOR = "Jon Dattorro",
  year = 1997,
  TITLE = "Effect Design 1: Reverberator and Other Filters",
  ADDRESS = "https://ccrma.stanford.edu/~dattorro/EffectDesignPart1.pdf",
}

@book{spectral_audio_processing,
  AUTHOR = "Julius O. Smith",
  TITLE = "Spectral Audio Signal Processing",
  PUBLISHER = "\url{https://ccrma.stanford.edu/~jos/sasp/}",
  YEAR = "accessed 20.04.2023",
  NOTE = "online book, 2011 edition",
}

@book{computational_music_synthesis,
  author = { Sean Luke },
  title = { Computational Music Synthesis },
  edition = { first },
  year = { 2021 },
  note = { Available for free at \url{http://cs.gmu.edu/~sean/book/synthesis/}},
}

@book{lisp_synthesis,
  author = { Nicky Hind },
  title = { Common Lisp Music (CLM) Tutorials },
  edition = { first },
  year = { 2021 },
  note = { Available for free at \url{
          https://ccrma.stanford.edu/software/clm/compmus/clm-tutorials/toc.html}
          },
}

@article{2020SciPy-NMeth,
  author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski,
            Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan
            and {van der Walt}, St{\'e}fan J. and Brett, Matthew and Wilson,
            Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew
            R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C
            J and Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and {
            VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and Cimrman,
            Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R.
            and Archibald, Anne M. and Ribeiro, Ant{\^o}nio H. and Pedregosa,
            Fabian and {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title = {{{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in
           Python}},
  journal = {Nature Methods},
  year = {2020},
  volume = {17},
  pages = {261--272},
  adsurl = {https://rdcu.be/b08Wh},
  doi = {10.1038/s41592-019-0686-2},
}

@inproceedings{parallel_evolutionary_optimization_synth_parameters,
  author = "Bozkurt, Batuhan and Y{\"u}ksel, Kamer Ali",
  editor = "Di Chio, Cecilia and Brabazon, Anthony and Di Caro, Gianni A. and
            Drechsler, Rolf and Farooq, Muddassar and Grahl, J{\"o}rn and
            Greenfield, Gary and Prins, Christian and Romero, Juan and Squillero,
            Giovanni and Tarantino, Ernesto and Tettamanzi, Andrea G. B. and
            Urquhart, Neil and Uyar, A. {\c{S}}ima",
  title = "Parallel Evolutionary Optimization of Digital Sound Synthesis
           Parameters",
  booktitle = "Applications of Evolutionary Computation",
  year = "2011",
  publisher = "Springer Berlin Heidelberg",
  address = "Berlin, Heidelberg",
  pages = "194--203",
  abstract = "In this research, we propose a novel parallelizable architecture
              for the optimization of various sound synthesis parameters. The
              architecture employs genetic algorithms to match the parameters of
              different sound synthesizer topologies to target sounds. The
              fitness function is evaluated in parallel to decrease its
              convergence time. Based on the proposed architecture, we have
              implemented a framework using the SuperCollider audio synthesis and
              programming environment and conducted several experiments. The
              results of the experiments have shown that the framework can be
              utilized for accurate estimation of the sound synthesis parameters
              at promising speeds.",
  isbn = "978-3-642-20520-0",
}

@inproceedings{peaq,
  author = {Khalifeh, Ala F. and Al-Tamimi, Abdel-Karim and Darabkh, Khalid A.},
  booktitle = {2017 International Conference on Wireless Communications, Signal
               Processing and Networking (WiSPNET)},
  title = {Perceptual evaluation of audio quality under lossy networks},
  year = {2017},
  volume = {},
  number = {},
  pages = {939-943},
  doi = {10.1109/WiSPNET.2017.8299900},
}

@misc{zhang2023language,
  title = {Language Models are Drummers: Drum Composition with Natural Language
           Pre-Training},
  author = {Li Zhang and Chris Callison-Burch},
  year = {2023},
  eprint = {2301.01162},
  archivePrefix = {arXiv},
  primaryClass = {cs.SD},
}

@article{mfcc,
  author = {Zheng, Fang and Zhang, Guoliang and Song, Zhanjiang},
  title = {Comparison of different implementations of MFCC},
  journal = {Journal of Computer Science and Technology},
  year = {2001},
  month = {Nov},
  day = {01},
  volume = {16},
  number = {6},
  pages = {582-589},
  abstract = {The performance of the Mel-Frequency Cepstrum Coefficients (MFCC)
              may be affected by (1) the number of filters, (2) the shape of
              filters, (3) the way in which filters are spaced, and (4) the way
              in which the power spectrum is warped. In this paper, several
              comparison experiments are done to find a best implementation. The
              traditional MFCC calculation excludes the 0th coefficient for the
              reason that it is regarded as somewhat unreliable. According to the
              analysis and experiments, the authors find that it can be regarded
              as the generalized frequency band energy (FBE) and is hence useful,
              which results in the FBE-MFCC. The authors also propose a better
              analysis, namely the auto-regressive analysis, on the frame energy,
              which outperform its 1st and/or 2nd order differential derivatives.
              Experiments with the ``863'' Speech Database show that, compared
              with the traditional MFCC with its corresponding auto-regressive
              analysis coefficients, the FBE-MFCC and the frame energy with their
              corresponding auto-regressive analysis coefficients form the best
              combination, reducing the Chinese syllable error rate (CSER) by
              about 10{\%}, while the FBE-MFCC with the corresponding
              auto-regressive analysis coefficients reduces CSER by 2.5{\%}.
              Comparison experiments are also done with a quite casual Chinese
              speech database, named Chinese Annotated Spontaneous Speech (CASS)
              corpus. The FBE-MFCC can reduce the error rate by about 2.9{\%} on
              an average.},
  issn = {1860-4749},
  doi = {10.1007/BF02943243},
  note = {\url{https://doi.org/10.1007/BF02943243}},
}

@misc{frechet_audio_distance,
  doi = {10.48550/ARXIV.1812.08466},
  note = {\url{https://arxiv.org/abs/1812.08466}},
  author = {Kilgour, Kevin and Zuluaga, Mauricio and Roblek, Dominik and Sharifi
            , Matthew},
  keywords = {Audio and Speech Processing (eess.AS), Sound (cs.SD), FOS:
              Electrical engineering, electronic engineering, information
              engineering, FOS: Electrical engineering, electronic engineering,
              information engineering, FOS: Computer and information sciences,
              FOS: Computer and information sciences},
  title = {Fréchet Audio Distance: A Metric for Evaluating Music Enhancement
           Algorithms},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license},
}

@inproceedings{ieee_synth_programming,
  author = {Faronbi, Daniel and Roman, Iran and Bello, Juan Pablo},
  booktitle = {ICASSP 2023 - 2023 IEEE International Conference on Acoustics,
               Speech and Signal Processing (ICASSP)},
  title = {Exploring Approaches to Multi-Task Automatic Synthesizer Programming},
  year = {2023},
  volume = {},
  number = {},
  pages = {1-5},
  doi = {10.1109/ICASSP49357.2023.10095540},
}

@inproceedings{mfcc_dtw,
  author = "Sood, Meenakshi and Jain, Shruti",
  editor = "Singh, Pradeep Kumar and Polkowski, Zdzislaw and Tanwar, Sudeep and
            Pandey, Sunil Kumar and Matei, Gheorghe and Pirvu, Daniela",
  title = "Speech Recognition Employing MFCC and Dynamic Time Warping Algorithm",
  booktitle = "Innovations in Information and Communication Technologies
               (IICT-2020)",
  year = "2021",
  publisher = "Springer International Publishing",
  address = "Cham",
  pages = "235--242",
  abstract = "Speech has been an integral part of human life acting as one of
              the five primitive senses of the human body. As such any software
              or application based upon speech recognition has a high degree of
              acceptance and a wide range of applications in defense, security,
              health care, and home automation. Speech is a waffling signal with
              varying characteristics at a high rate. When examined over a very
              short scale of time, it can be considered as a stationary signal
              with very small variations. In this paper, authors have worked upon
              the detection of a single user using multiple isolated words as
              speech signals. For designing the system, feature extraction using
              Mel-frequency cepstral coefficients (MFCCs) and feature matching
              using dynamic time warping (DTW) are considered as the designing of
              the system because of its simplicity and efficiency. Short-time
              spectral analysis is adopted which is the main part of the MFCC
              algorithm used in feature extraction. To compare any two signals
              varying in speed or having phase difference between them, DTW is
              used. Since two spoken words can never be the same, the DTW
              algorithm is best suited to compare two words.",
  isbn = "978-3-030-66218-9",
}

@article{dtw_time_complexity,
  author = {Gold, Omer and Sharir, Micha},
  title = {Dynamic Time Warping and Geometric Edit Distance: Breaking the
           Quadratic Barrier},
  year = {2018},
  issue_date = {October 2018},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {14},
  number = {4},
  issn = {1549-6325},
  url = {https://doi.org/10.1145/3230734},
  doi = {10.1145/3230734},
  abstract = {Dynamic Time Warping (DTW) and Geometric Edit Distance (GED) are
              basic similarity measures between curves or general temporal
              sequences (e.g., time series) that are represented as sequences of
              points in some metric space (X, dist). The DTW and GED measures are
              massively used in various fields of computer science and
              computational biology. Consequently, the tasks of computing these
              measures are among the core problems in P. Despite extensive
              efforts to find more efficient algorithms, the best-known
              algorithms for computing the DTW or GED between two sequences of
              points in X = Rd are long-standing dynamic programming algorithms
              that require quadratic runtime, even for the one-dimensional case d
              = 1, which is perhaps one of the most used in practice.In this
              article, we break the nearly 50-year-old quadratic time bound for
              computing DTW or GED between two sequences of n points in R by
              presenting deterministic algorithms that run in O(n2 log log log n/
              log log n) time. Our algorithms can be extended to work also for
              higher-dimensional spaces Rd, for any constant d, when the
              underlying distance-metric dist is polyhedral (e.g., L1, Linfin).},
  journal = {ACM Trans. Algorithms},
  month = {aug},
  articleno = {50},
  numpages = {17},
  keywords = {point matching, time series, geometric edit distance, Dynamic time
              warping, geometric matching},
}
